/*
 * Copyright 2024 CloudWeGo Authors
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package anonymizer

import (
	"bytes"
	"context"
	"encoding/json"
	"fmt"
	"io"
	"regexp"
	"strings"
	"unicode"

	"github.com/rotisserie/eris"

	"github.com/cloudwego/eino/components/model"
	"github.com/cloudwego/eino/components/prompt"
	"github.com/cloudwego/eino/schema"
)

// placeholderRegex matches placeholder patterns like <...>
var placeholderRegex = regexp.MustCompile(`<[^>]+>`)

// RestoreFailure 表示一个无法还原的占位符及其失败原因。
type RestoreFailure struct {
	// Placeholder 是归一化后的占位符字符串 (如 "<个人信息[1].姓名.全名>")
	Placeholder string
	// Reason 是失败原因: "not_found" (实体不存在) 或 "empty_values" (实体无值)
	Reason string
}

// Anonymizer 定义文本敏感信息脱敏的核心接口。
// 实现此接口的类型应当能够：
//  1. 将原始文本中的敏感实体替换为占位符
//  2. 记录实体映射关系以支持还原
//  3. 支持流式输出以改善用户体验
type Anonymizer interface {
	// Anonymize 流式脱敏文本，实时写入 writer
	// 返回识别到的实体列表和可能的错误
	Anonymize(ctx context.Context, types []string, text string, writer io.Writer) ([]*Entity, error)

	// RestoreText 使用实体映射还原脱敏文本，流式写入 writer
	// 返回无法还原的占位符列表(如果为空则全部还原成功)
	RestoreText(ctx context.Context, entities []*Entity, text string, writer io.Writer) ([]RestoreFailure, error)
}

// HasHidePair 是基于 <<<PAIR>>> 分隔符格式的 Anonymizer 实现。
// 它使用 LLM 生成脱敏文本和实体映射，响应格式为：
//
//	<脱敏文本>
//	<<<PAIR>>>
//	<JSON 映射>
//
// 此实现支持流式输出，在遇到 <<<PAIR>>> 标记前将 token 实时写入输出。
type HasHidePair struct {
	anonymizeTemplate *prompt.DefaultChatTemplate
	llm               model.BaseChatModel
}

// createAnonymizeMessages creates messages for anonymization.
func (h *HasHidePair) createAnonymizeMessages(ctx context.Context, types []string, text string) ([]*schema.Message, error) {
	encodedTypes, err := json.Marshal(types)
	if err != nil {
		return nil, eris.Wrap(err, "failed to marshal types")
	}

	messages, err := h.anonymizeTemplate.Format(ctx, map[string]any{
		"types": string(encodedTypes),
		"text":  text,
	})

	if err != nil {
		return nil, eris.Wrap(err, "failed to format message")
	}

	return messages, nil
}

// parseAnonymizeResponse parses the complete LLM response to extract anonymized text and entities.
// The response format is: <anonymized_text>\n<<<PAIR>>>\n<JSON_mapping>
func parseAnonymizeResponse(responseContent string) (string, []*Entity, error) {
	splited := strings.SplitN(responseContent, "<<<PAIR>>>", 2)
	if len(splited) != 2 {
		return "", nil, fmt.Errorf("invalid response format, expected 2 parts but got %d, %s", len(splited), responseContent)
	}

	anonymizedText := strings.TrimSpace(splited[0])
	mappingStr := strings.TrimSpace(splited[1])

	entities, err := parseAnonymizeEntities([]byte(mappingStr))
	if err != nil {
		return "", nil, err
	}

	return anonymizedText, entities, nil
}

// parseAnonymizeResponse parses the complete LLM response to extract anonymized text and entities.
func parseAnonymizeEntities(entitiesStr []byte) ([]*Entity, error) {

	var mapping map[string][]string
	err := json.Unmarshal(entitiesStr, &mapping)
	if err != nil {
		return nil, eris.Wrap(err, "failed to unmarshal mapping")
	}

	// key format: <EntityType[ID].Category.Detail>
	keyParseRe := regexp.MustCompile(`<(.+?)\[(.+?)\]\.(.+?)\.(.+?)>`)
	entities := make([]*Entity, 0, len(mapping))
	for key, values := range mapping {
		matches := keyParseRe.FindStringSubmatch(key)
		if len(matches) != 5 {
			return nil, fmt.Errorf("invalid key format: %s", key)
		}

		entityType := matches[1]
		id := matches[2]
		category := matches[3]
		detail := matches[4]

		entities = append(entities, &Entity{
			Key:        key,
			EntityType: entityType,
			ID:         id,
			Category:   category,
			Detail:     detail,
			Values:     values,
		})
	}

	return entities, nil
}

// Anonymize anonymizes the given text with streaming output.
// It streams the anonymized text to the provided writer as tokens are generated by the LLM.
// The entities mapping is returned after the stream completes.
//
// Parameters:
//   - ctx: Context for cancellation and timeouts
//   - types: Entity types to detect (e.g., ["个人信息", "业务信息"])
//   - text: Input text to anonymize
//   - writer: Destination for streaming output (e.g., os.Stdout, file, io.MultiWriter)
//
// Returns:
//   - entities: List of detected entities with their mappings
//   - error: Any error during streaming, writing, or parsing
//
// Example:
//
//	var buf bytes.Buffer
//	entities, err := anon.Anonymize(ctx, types, input, &buf)
//	if err != nil {
//	    return err
//	}
//	fmt.Printf("Streamed output: %s\n", buf.String())
//	fmt.Printf("Entities: %+v\n", entities)
func (h *HasHidePair) Anonymize(ctx context.Context, types []string, text string, writer io.Writer) ([]*Entity, error) {
	messages, err := h.createAnonymizeMessages(ctx, types, text)
	if err != nil {
		return nil, eris.Wrap(err, "failed to create anonymize messages")
	}

	// Get streaming reader from LLM
	streamReader, err := h.llm.Stream(ctx, messages)
	if err != nil {
		// Fallback to Generate if Stream is not supported (e.g., in tests)
		response, genErr := h.llm.Generate(ctx, messages)
		if genErr != nil {
			return nil, eris.Wrap(genErr, "failed to generate response (stream fallback)")
		}
		// Parse response to extract anonymized text and entities
		anonymizedText, entities, parseErr := parseAnonymizeResponse(response.Content)
		if parseErr != nil {
			return nil, eris.Wrap(parseErr, "failed to parse response")
		}
		// Write only the anonymized text to writer
		if _, writeErr := writer.Write([]byte(anonymizedText)); writeErr != nil {
			return nil, eris.Wrap(writeErr, "failed to write to output")
		}
		return entities, nil
	}

	var buffer bytes.Buffer
	foundPair := false

	for {
		msg, err := streamReader.Recv()
		if err == io.EOF {
			break
		}
		if err != nil {
			return nil, eris.Wrap(err, "failed to receive stream token")
		}

		if foundPair {
			// After <<<PAIR>>>, collect JSON tokens
			buffer.WriteString(msg.Content)
			continue
		}

		buffer.WriteString(msg.Content)
		if !strings.Contains(msg.Content, "\n") {
			continue
		} else if strings.Contains(buffer.String(), "<<<PAIR>>>") {
			buffer.Reset()
			foundPair = true
			continue
		}

		_, err = writer.Write(buffer.Bytes())
		if err != nil {
			return nil, eris.Wrap(err, "failed to write to output")
		}
		buffer.Reset()
	}

	entitesBytes := buffer.Bytes()
	entities, err := parseAnonymizeEntities(entitesBytes)
	if err != nil {
		return nil, eris.Wrapf(err, "failed to parse anonymize response: %s", string(entitesBytes))
	}

	return entities, nil
}

// RestoreText restores the original text from the anonymized text using the provided entities.
// It supports fuzzy matching of placeholders with format variations (extra spaces, Chinese punctuation, fullwidth characters).
// The restored text is written to the writer, and a list of failures is returned.
//
// Returns:
//   - failures: List of placeholders that could not be restored, with reasons
//   - error: Any error during writing
func (h *HasHidePair) RestoreText(ctx context.Context, entities []*Entity, text string, writer io.Writer) ([]RestoreFailure, error) {
	// Build two maps: one for entities with values, one for entities without values
	entityMap := make(map[string]string)
	emptyKeys := make(map[string]bool)

	for _, entity := range entities {
		normalizedKey := normalizePlaceholder(entity.Key)
		if len(entity.Values) == 0 {
			emptyKeys[normalizedKey] = true
		} else {
			entityMap[normalizedKey] = entity.Values[0]
		}
	}

	// Collect failures
	var failures []RestoreFailure
	seenFailures := make(map[string]bool) // Deduplication

	// Stream replacement
	lastIndex := 0
	matches := placeholderRegex.FindAllStringIndex(text, -1)

	for _, match := range matches {
		// Write text before placeholder
		if _, err := writer.Write([]byte(text[lastIndex:match[0]])); err != nil {
			return nil, eris.Wrap(err, "failed to write to output")
		}

		// Process placeholder
		placeholder := text[match[0]:match[1]]
		normalizedKey := normalizePlaceholder(placeholder)

		if value, exists := entityMap[normalizedKey]; exists {
			// Restore succeeded
			if _, err := writer.Write([]byte(value)); err != nil {
				return nil, eris.Wrap(err, "failed to write to output")
			}
		} else {
			// Restore failed, keep placeholder
			if _, err := writer.Write([]byte(placeholder)); err != nil {
				return nil, eris.Wrap(err, "failed to write to output")
			}

			// Record failure reason
			if !seenFailures[normalizedKey] {
				reason := "not_found"
				if emptyKeys[normalizedKey] {
					reason = "empty_values"
				}
				failures = append(failures, RestoreFailure{
					Placeholder: normalizedKey,
					Reason:      reason,
				})
				seenFailures[normalizedKey] = true
			}
		}

		lastIndex = match[1]
	}

	// Write remaining text
	if _, err := writer.Write([]byte(text[lastIndex:])); err != nil {
		return nil, eris.Wrap(err, "failed to write to output")
	}

	return failures, nil
}

// normalizePlaceholder normalizes a placeholder string to a standard format for matching.
// It handles common format variations from external tools (ChatGPT, text editors):
//   - Removes all whitespace (spaces, tabs, newlines)
//   - Converts Chinese punctuation to English: 。→. ，→, 【→[ 】→]
//   - Converts fullwidth characters to halfwidth (ASCII range)
//
// Normalization rules:
//  1. Extract content between < and >
//  2. Remove all whitespace characters
//  3. Convert Chinese punctuation to English equivalents
//  4. Convert fullwidth ASCII (U+FF01-U+FF5E) to halfwidth (U+0021-U+007E)
//
// Examples:
//   - < 业务信息 [2]. 系统。名称 > → <业务信息[2].系统.名称>
//   - <　个人信息　[　０　].　姓名　> → <个人信息[0].姓名>
//   - <个人信息[0].姓名.全名> → <个人信息[0].姓名.全名> (unchanged)
//
// If the input is not a valid placeholder (missing < or >), it returns unchanged.
func normalizePlaceholder(placeholder string) string {
	// 1. Extract content between < and >
	if !strings.HasPrefix(placeholder, "<") || !strings.HasSuffix(placeholder, ">") {
		return placeholder // Not a placeholder, return as-is
	}

	content := placeholder[1 : len(placeholder)-1]

	// 2. Remove all whitespace
	content = strings.Map(func(r rune) rune {
		if unicode.IsSpace(r) {
			return -1 // Remove
		}
		return r
	}, content)

	// 3. Convert Chinese punctuation to English
	replacements := map[string]string{
		"。": ".",
		"，": ",",
		"【": "[",
		"】": "]",
	}
	for old, new := range replacements {
		content = strings.ReplaceAll(content, old, new)
	}

	// 4. Convert fullwidth to halfwidth (ASCII range)
	content = strings.Map(func(r rune) rune {
		// Fullwidth ASCII: U+FF01 to U+FF5E
		// Halfwidth ASCII: U+0021 to U+007E
		if r >= 0xFF01 && r <= 0xFF5E {
			return r - 0xFEE0 // Convert to halfwidth
		}
		return r
	}, content)

	return "<" + content + ">"
}

// NewHashHidePair 创建一个基于 <<<PAIR>>> 格式的 Anonymizer 实现。
// 该实现使用 LLM 进行文本脱敏，响应格式为脱敏文本和 JSON 映射由 <<<PAIR>>> 分隔。
func NewHashHidePair(chatModel model.BaseChatModel) (Anonymizer, error) {
	anonymizeTemplate := prompt.FromMessages(schema.FString,
		schema.UserMessage(`Anonymize the text with the given entity types, then output the tag-to-original mapping; if nothing is found, reply "None".
Specified types: {types}
<text>{text}</text>`),
	)

	return &HasHidePair{
		anonymizeTemplate: anonymizeTemplate,
		llm:               chatModel,
	}, nil
}
